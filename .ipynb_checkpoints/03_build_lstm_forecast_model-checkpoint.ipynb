{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy                as np\n",
    "import pandas               as pd\n",
    "\n",
    "from keras.models          import Sequential\n",
    "from keras.layers          import Dense, LSTM\n",
    "\n",
    "from math                  import sqrt\n",
    "from matplotlib            import pyplot\n",
    "from numpy                 import array, mean, std\n",
    "\n",
    "from sklearn.metrics       import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working space\n",
    "def_metric = 'incidence'\n",
    "def_state  = 'Massachusetts'\n",
    "def_town   = 'Middlesex, Massachusetts, US'\n",
    "min_date   = '2020-03-09'\n",
    "\n",
    "# column identification map\n",
    "dim_cols       = [ 'town', 'date' ]\n",
    "uni_var_cols   = [ def_metric ]\n",
    "multi_var_cols = [ 'incidence_rate_pct', 'deaths', 'population' ]\n",
    "all_cols       = dim_cols + multi_var_cols + uni_var_cols\n",
    "drop_cols      = [ 'town' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data():\n",
    "    \"\"\"prep_data - read data, format & return dataframe\n",
    "    \"\"\"\n",
    "    df_all = pd.read_csv(\"covid19_2020_04_05.csv\")\n",
    "    \n",
    "    # rename map\n",
    "    new_col_names = {\n",
    "        def_metric:'y'\n",
    "    }\n",
    "    \n",
    "    # filter down to relevant cols and rows based on town and date\n",
    "    df = df_all[all_cols]\n",
    "    df = df[df['town'] == def_town]\n",
    "    df = df[df['date'] >= min_date]\n",
    "\n",
    "    # rename\n",
    "    df.rename(columns=new_col_names, inplace=True)\n",
    "\n",
    "    # set index (for time-series modeling)\n",
    "    df = df.set_index('date')\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "    train, test = data[:-n_test], data[-n_test:]\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "# transform list into supervised learning format\n",
    "def series_to_supervised(data, n_in, n_out=1):\n",
    "    df = pd.DataFrame(data)\n",
    "    cols = list()\n",
    "    \n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        \n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        \n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    \n",
    "    # drop rows with NaN values\n",
    "    agg.dropna(inplace=True)\n",
    "    \n",
    "    return agg.values\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "    rmse = sqrt(mean_squared_error(actual, predicted))\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "# difference dataset\n",
    "def difference(data, interval):\n",
    "    diff_data = [data[i] - data[i - interval] for i in range(interval, len(data))]\n",
    "    \n",
    "    return diff_data\n",
    "\n",
    "# fit a model\n",
    "def model_fit(train, config):\n",
    "    # unpack config\n",
    "    n_input, n_nodes, n_epochs, n_batch, n_diff = config\n",
    "    \n",
    "    # prepare data (useful for seasonal differencing, which\n",
    "    # is not applicable here)\n",
    "    if n_diff > 0:\n",
    "        train = difference(train, n_diff)\n",
    "    \n",
    "    data = series_to_supervised(train, n_input)\n",
    "    train_x, train_y = data[:, :-1], data[:, -1]\n",
    "    train_x = train_x.reshape((train_x.shape[0], train_x.shape[1], 1))\n",
    "    \n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_nodes, activation='relu', input_shape=(n_input, 1)))\n",
    "    model.add(Dense(n_nodes, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    # fit\n",
    "    model.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=0)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# forecast with a pre-fit model\n",
    "def model_predict(model, history, config):\n",
    "    # unpack config\n",
    "    n_input, _, _, _, n_diff = config\n",
    "    \n",
    "    # prepare data\n",
    "    correction = 0.0\n",
    "    if n_diff > 0:\n",
    "        correction = history[-n_diff]\n",
    "        history = difference(history, n_diff)\n",
    "    \n",
    "    x_input = array(history[-n_input:]).reshape((1, n_input, 1))\n",
    "    \n",
    "    # forecast\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "    pred = correction + yhat[0]\n",
    "    \n",
    "    return pred\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "    predictions = list()\n",
    "    \n",
    "    # split dataset\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    \n",
    "    # fit model\n",
    "    model = model_fit(train, cfg)\n",
    "    \n",
    "    # seed history with training dataset\n",
    "    history = [ x for x in train ]\n",
    "    \n",
    "    # step over each time-step in the test set\n",
    "    for i in range(len(test)):\n",
    "        # fit model and make forecast for history\n",
    "        yhat = model_predict(model, history, cfg)\n",
    "        \n",
    "        # store forecast in list of predictions\n",
    "        predictions.append(yhat)\n",
    "        \n",
    "        # add actual observation to history for the next loop\n",
    "        history.append(test[i])\n",
    "    \n",
    "    # estimate prediction error\n",
    "    error = measure_rmse(test, predictions)\n",
    "    print(f\"RMSE = {error:.0f}\")\n",
    "    \n",
    "    return error, test, predictions\n",
    "\n",
    "# repeat evaluation of a config\n",
    "def repeat_evaluate(data, n_test, config, n_repeats=10):\n",
    "    scores = []\n",
    "\n",
    "    # fit and evaluate the model n times\n",
    "    for _ in range(n_repeats):\n",
    "        score, test, pred = walk_forward_validation(data, n_test, config)\n",
    "        scores.append(score)\n",
    "        \n",
    "    return scores\n",
    "\n",
    "# summarize model performance\n",
    "def summarize_scores(scores):\n",
    "    # print a summary\n",
    "    scores_m, score_std = mean(scores), std(scores)\n",
    "    print(f\"{scores_m:.2f} RMSE (+/- {score_std:.2f})\")\n",
    "    \n",
    "    # box and whisker plot\n",
    "    pyplot.boxplot(scores)\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all():\n",
    "    \"\"\"run_all - orchestrator\n",
    "    \"\"\"\n",
    "    # Prep data\n",
    "    df = prep_data()\n",
    "    data = df['y'].values\n",
    "    \n",
    "    # Build model 10 times to get a distribution of errors\n",
    "    if (viz_data == True):\n",
    "        #visualize modeling data set\n",
    "        print(df.shape)\n",
    "        display(df)\n",
    "        df['y'].plot(figsize=(12,8))\n",
    "\n",
    "    # Build model 1 time\n",
    "    if (bld_mdl == True):\n",
    "        score, test, pred = walk_forward_validation(data, n_test, config)\n",
    "        for tpl in zip(test, pred):\n",
    "            print(tpl)\n",
    "\n",
    "    if (bld_smry == True):\n",
    "        # error distribtions\n",
    "        scores = repeat_evaluate(data, n_test, config)\n",
    "        summarize_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 100\n",
      "(1141, array([1164.3784], dtype=float32))\n",
      "(1340, array([1345.0587], dtype=float32))\n",
      "(1582, array([1571.3748], dtype=float32))\n",
      "(1870, array([1848.752], dtype=float32))\n",
      "(2202, array([2181.0554], dtype=float32))\n",
      "(2468, array([2565.8557], dtype=float32))\n",
      "(2632, array([2874.857], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "viz_data   = False\n",
    "bld_mdl    = False\n",
    "bld_smry   = False\n",
    "sv_res     = False\n",
    "\n",
    "#viz_data  = True\n",
    "bld_mdl    = True\n",
    "#bld_smry   = True\n",
    "#sv_res     = True\n",
    "\n",
    "# number of periods in hold-out\n",
    "n_test = 7\n",
    "\n",
    "# n_inputs, n_nodes, n_epochs, n_batch, n_diff\n",
    "config = [ 1, 50, 200, 5, 0 ]\n",
    "\n",
    "run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prep_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'op_exl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-4ae54a04d834>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExcelWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_exl\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m       \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msheet_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"op\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'op_exl' is not defined"
     ]
    }
   ],
   "source": [
    "with pd.ExcelWriter(\"covid_ms_data.xlsx\") as writer:\n",
    "      df.to_excel(writer, sheet_name = \"op\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
